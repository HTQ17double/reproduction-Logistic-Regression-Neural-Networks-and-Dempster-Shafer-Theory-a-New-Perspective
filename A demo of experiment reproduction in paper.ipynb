{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonENV\\p38tf25\\lib\\site-packages\\scipy\\__init__.py:173: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Limit GPU memory usage\n",
    "using_gpu_index = 0\n",
    "gpu_list = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpu_list) > 0:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpu_list[using_gpu_index], \n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Got no GPUs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and Dempster-Shafer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Heart Disease data\n",
    "data = pd.read_csv(\"https://hastie.su.domains/ElemStatLearn/datasets/SAheart.data\", index_col=0)\n",
    "data_new = data[['ldl','age','chd']]\n",
    "X_train = data_new.values[:300,:2]\n",
    "Y_train = data_new.values[:300,[2]]\n",
    "X_test = data_new.values[300:,:2]\n",
    "Y_test = data_new.values[300:,[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonENV\\p38tf25\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7469135802469136"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14177157 0.05555956]\n",
      "[-3.70800497]\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "w = model.coef_[0]                                \n",
    "b = model.intercept_\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve for alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = w[0]\n",
    "b2 = w[1]\n",
    "b0 = b[0]\n",
    "u1 = np.mean(X_train[:,0] * b1)\n",
    "u2 = np.mean(X_train[:,1] * b2)\n",
    "a1 = b0/2 + 1/2*(b1*u1+b2*u2) - b1*u1\n",
    "a2 = b0/2 + 1/2*(b1*u1+b2*u2) - b2*u2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w+ and w-\n",
    "base = np.zeros((len(X_test),1))\n",
    "w_plus = np.max(np.concatenate((X_test[:,[0]]*b1+a1,base),axis=1),1) + np.max(np.concatenate((X_test[:,[1]]*b2+a2,base),axis=1),1)\n",
    "w_minus = np.max(np.concatenate((-(X_test[:,[0]]*b1+a1),base),axis=1),1) + np.max(np.concatenate((-(X_test[:,[1]]*b2+a2),base),axis=1),1)\n",
    "# mass function\n",
    "conflict = 1-(1-np.exp(-1*w_plus))*(1-np.exp(-1*w_minus))\n",
    "m1 = (1-np.exp(-1*w_plus))*np.exp(-1*w_minus)/conflict\n",
    "m2 = (1-np.exp(-1*w_minus))*np.exp(-1*w_plus)/conflict\n",
    "m0 = np.exp(-1*w_plus)*np.exp(-1*w_minus)/conflict\n",
    "m1 = m1.reshape(-1,1)\n",
    "m2 = m2.reshape(-1,1)\n",
    "m0 = m0.reshape(-1,1)\n",
    "m = np.concatenate((m2,m1,m0),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision based on ID rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_upper_lower = []\n",
    "results = []\n",
    "for i in range(len(X_test)):\n",
    "    upper1 = 1-m[i][0]\n",
    "    lower1 = 1-m[i][0]-m[i][2]\n",
    "    upper2 = 1-m[i][1]\n",
    "    lower2 = 1-m[i][1]-m[i][2]\n",
    "    if lower2>upper1:\n",
    "        results.append(0)\n",
    "    elif lower1>upper2:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(2)\n",
    "    R_upper_lower.append([[lower1,upper1],[lower2,upper2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe the difference in accuracy between the probabilistic decision-making results obtained based on likelihood and the direct decision-making results of the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7469135802469136"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1=(m[:,1]+m[:,2])/((m[:,1]+m[:,2])+(m[:,0]+m[:,2]))\n",
    "predict = np.where(p1>0.5,1,0)\n",
    "np.mean(predict == Y_test.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((3,2))\n",
    "for i in range(len(X_test)):\n",
    "    pred = int(results[i])\n",
    "    true = int(Y_test[i][0])\n",
    "    confusion_matrix[pred,true] = confusion_matrix[pred,true]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47530864, 0.07407407],\n",
       "       [0.06790123, 0.08641975],\n",
       "       [0.14814815, 0.14814815]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix/np.sum(confusion_matrix)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Dempster-Shafer Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Generate Gaussian Multi-category Data\n",
    "# Generate unit matrix\n",
    "I = np.zeros((2,2))\n",
    "for i in range(2):\n",
    "    I[i,i]=1\n",
    "# Mean\n",
    "mean1 = mean2 = [0.0,0.0]\n",
    "mean3 = [1,-1]\n",
    "# Covariance matrix\n",
    "sigma1 = 0.1*I\n",
    "sigma2 = 0.5*I\n",
    "sigma3 = [[0.3,-0.15],[-0.15,0.3]]\n",
    "\n",
    "mean = {0:mean1,1:mean2,2:mean3}\n",
    "sigma = {0:sigma1,1:sigma2,2:sigma3}\n",
    "\n",
    "# Generate Gaussian Multi-category Training Data\n",
    "for i in range(3):\n",
    "    if i ==0:\n",
    "        datai = np.random.multivariate_normal(mean=mean[i], cov=sigma[i], size=300)\n",
    "        label = np.zeros((300,1))+i\n",
    "        datai = np.concatenate((datai,label),-1)\n",
    "        data = datai\n",
    "    else:\n",
    "        datai = np.random.multivariate_normal(mean=mean[i], cov=sigma[i], size=300)\n",
    "        label = np.zeros((300,1))+i\n",
    "        datai = np.concatenate((datai,label),-1)\n",
    "        data = np.concatenate((data,datai))\n",
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data,random_state=1999)\n",
    "data = shuffle(data,random_state=2005)\n",
    "data = shuffle(data,random_state=2015)\n",
    "data = shuffle(data,random_state=2018)\n",
    "data = shuffle(data,random_state=2022)\n",
    "\n",
    "# Generate Gaussian Multi-category Testing Data\n",
    "for i in range(3):\n",
    "    if i ==0:\n",
    "        datai = np.random.multivariate_normal(mean=mean[i], cov=sigma[i], size=200)\n",
    "        label = np.zeros((200,1))+i\n",
    "        datai = np.concatenate((datai,label),-1)\n",
    "        data_test = datai\n",
    "    else:\n",
    "        datai = np.random.multivariate_normal(mean=mean[i], cov=sigma[i], size=200)\n",
    "        label = np.zeros((200,1))+i\n",
    "        datai = np.concatenate((datai,label),-1)\n",
    "        data_test = np.concatenate((data_test,datai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(3):\n",
    "    datai = data_test[data_test[:,2]==i]\n",
    "    plt.scatter(datai[:,0],datai[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set division and Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonENV\\p38tf25\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 1s 19ms/step - loss: 1.1991 - acc: 0.3159 - val_loss: 1.1420 - val_acc: 0.2741\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.1837 - acc: 0.3143 - val_loss: 1.1199 - val_acc: 0.2704\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.1626 - acc: 0.2746 - val_loss: 1.1014 - val_acc: 0.2593\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.1437 - acc: 0.2984 - val_loss: 1.0864 - val_acc: 0.2148\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.1175 - acc: 0.2730 - val_loss: 1.0743 - val_acc: 0.2000\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.1112 - acc: 0.2810 - val_loss: 1.0629 - val_acc: 0.2926\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0960 - acc: 0.2794 - val_loss: 1.0520 - val_acc: 0.4778\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0699 - acc: 0.3444 - val_loss: 1.0411 - val_acc: 0.5444\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0773 - acc: 0.3698 - val_loss: 1.0308 - val_acc: 0.5519\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0557 - acc: 0.3619 - val_loss: 1.0207 - val_acc: 0.5556\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0486 - acc: 0.3873 - val_loss: 1.0100 - val_acc: 0.5630\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0354 - acc: 0.4111 - val_loss: 0.9992 - val_acc: 0.5741\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0218 - acc: 0.4587 - val_loss: 0.9875 - val_acc: 0.5815\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0194 - acc: 0.4603 - val_loss: 0.9760 - val_acc: 0.5815\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0083 - acc: 0.4635 - val_loss: 0.9639 - val_acc: 0.5852\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9977 - acc: 0.4952 - val_loss: 0.9513 - val_acc: 0.5852\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9822 - acc: 0.4857 - val_loss: 0.9384 - val_acc: 0.5852\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9827 - acc: 0.4794 - val_loss: 0.9261 - val_acc: 0.5852\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9586 - acc: 0.4984 - val_loss: 0.9135 - val_acc: 0.5852\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9465 - acc: 0.5000 - val_loss: 0.9008 - val_acc: 0.5889\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9448 - acc: 0.5095 - val_loss: 0.8880 - val_acc: 0.5889\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9297 - acc: 0.4873 - val_loss: 0.8756 - val_acc: 0.5926\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9147 - acc: 0.5143 - val_loss: 0.8634 - val_acc: 0.5926\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9086 - acc: 0.5048 - val_loss: 0.8515 - val_acc: 0.5926\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8985 - acc: 0.5206 - val_loss: 0.8395 - val_acc: 0.5926\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8904 - acc: 0.5286 - val_loss: 0.8277 - val_acc: 0.5926\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8845 - acc: 0.5333 - val_loss: 0.8165 - val_acc: 0.5926\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8667 - acc: 0.5349 - val_loss: 0.8059 - val_acc: 0.5926\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8714 - acc: 0.5286 - val_loss: 0.7960 - val_acc: 0.5889\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8484 - acc: 0.5333 - val_loss: 0.7866 - val_acc: 0.6000\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8263 - acc: 0.5651 - val_loss: 0.7770 - val_acc: 0.6296\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8331 - acc: 0.5571 - val_loss: 0.7682 - val_acc: 0.6407\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8336 - acc: 0.5698 - val_loss: 0.7597 - val_acc: 0.6444\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8105 - acc: 0.5778 - val_loss: 0.7512 - val_acc: 0.6481\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8157 - acc: 0.6159 - val_loss: 0.7436 - val_acc: 0.6519\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8051 - acc: 0.5794 - val_loss: 0.7361 - val_acc: 0.6593\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8121 - acc: 0.5587 - val_loss: 0.7290 - val_acc: 0.6667\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8008 - acc: 0.5905 - val_loss: 0.7228 - val_acc: 0.6667\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7858 - acc: 0.5968 - val_loss: 0.7169 - val_acc: 0.6630\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7770 - acc: 0.5825 - val_loss: 0.7111 - val_acc: 0.6852\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7692 - acc: 0.6159 - val_loss: 0.7056 - val_acc: 0.6963\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7691 - acc: 0.6175 - val_loss: 0.7003 - val_acc: 0.6963\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7629 - acc: 0.6444 - val_loss: 0.6956 - val_acc: 0.7259\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7580 - acc: 0.6540 - val_loss: 0.6914 - val_acc: 0.7148\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7638 - acc: 0.6333 - val_loss: 0.6872 - val_acc: 0.7185\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7570 - acc: 0.6540 - val_loss: 0.6830 - val_acc: 0.7259\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7548 - acc: 0.6365 - val_loss: 0.6798 - val_acc: 0.7370\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7526 - acc: 0.6175 - val_loss: 0.6767 - val_acc: 0.7259\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7223 - acc: 0.6683 - val_loss: 0.6732 - val_acc: 0.7296\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7199 - acc: 0.6365 - val_loss: 0.6693 - val_acc: 0.7481\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7449 - acc: 0.6460 - val_loss: 0.6658 - val_acc: 0.7481\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7350 - acc: 0.6683 - val_loss: 0.6635 - val_acc: 0.7444\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7363 - acc: 0.6460 - val_loss: 0.6613 - val_acc: 0.7370\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7323 - acc: 0.6698 - val_loss: 0.6580 - val_acc: 0.7407\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7262 - acc: 0.6810 - val_loss: 0.6552 - val_acc: 0.7407\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7085 - acc: 0.6794 - val_loss: 0.6526 - val_acc: 0.7407\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7088 - acc: 0.6889 - val_loss: 0.6504 - val_acc: 0.7370\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7189 - acc: 0.6508 - val_loss: 0.6481 - val_acc: 0.7370\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7206 - acc: 0.6889 - val_loss: 0.6461 - val_acc: 0.7333\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7228 - acc: 0.6889 - val_loss: 0.6436 - val_acc: 0.7407\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7021 - acc: 0.6746 - val_loss: 0.6411 - val_acc: 0.7444\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7088 - acc: 0.6810 - val_loss: 0.6387 - val_acc: 0.7444\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7059 - acc: 0.6714 - val_loss: 0.6365 - val_acc: 0.7407\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7138 - acc: 0.6762 - val_loss: 0.6346 - val_acc: 0.7296\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6882 - acc: 0.6984 - val_loss: 0.6322 - val_acc: 0.7333\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7183 - acc: 0.6746 - val_loss: 0.6298 - val_acc: 0.7370\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7030 - acc: 0.6794 - val_loss: 0.6279 - val_acc: 0.7444\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6884 - acc: 0.7206 - val_loss: 0.6264 - val_acc: 0.7481\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6998 - acc: 0.6841 - val_loss: 0.6247 - val_acc: 0.7444\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7051 - acc: 0.6873 - val_loss: 0.6232 - val_acc: 0.7444\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6912 - acc: 0.6968 - val_loss: 0.6221 - val_acc: 0.7481\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7063 - acc: 0.6889 - val_loss: 0.6209 - val_acc: 0.7370\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6879 - acc: 0.7016 - val_loss: 0.6194 - val_acc: 0.7333\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6910 - acc: 0.6968 - val_loss: 0.6188 - val_acc: 0.7370\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6701 - acc: 0.7190 - val_loss: 0.6180 - val_acc: 0.7370\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6705 - acc: 0.6921 - val_loss: 0.6170 - val_acc: 0.7370\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6934 - acc: 0.6905 - val_loss: 0.6160 - val_acc: 0.7370\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6725 - acc: 0.7016 - val_loss: 0.6147 - val_acc: 0.7370\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6889 - acc: 0.7016 - val_loss: 0.6133 - val_acc: 0.7444\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7076 - acc: 0.6746 - val_loss: 0.6124 - val_acc: 0.7444\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6624 - acc: 0.7206 - val_loss: 0.6116 - val_acc: 0.7407\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6739 - acc: 0.6905 - val_loss: 0.6103 - val_acc: 0.7407\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6793 - acc: 0.7063 - val_loss: 0.6091 - val_acc: 0.7481\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6719 - acc: 0.6905 - val_loss: 0.6080 - val_acc: 0.7444\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6646 - acc: 0.7063 - val_loss: 0.6071 - val_acc: 0.7444\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6745 - acc: 0.7127 - val_loss: 0.6064 - val_acc: 0.7444\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6596 - acc: 0.7063 - val_loss: 0.6055 - val_acc: 0.7444\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6882 - acc: 0.7270 - val_loss: 0.6054 - val_acc: 0.7444\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6780 - acc: 0.6952 - val_loss: 0.6049 - val_acc: 0.7407\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6593 - acc: 0.7222 - val_loss: 0.6047 - val_acc: 0.7444\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6644 - acc: 0.7143 - val_loss: 0.6043 - val_acc: 0.7407\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6543 - acc: 0.7159 - val_loss: 0.6030 - val_acc: 0.7444\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6616 - acc: 0.7143 - val_loss: 0.6018 - val_acc: 0.7444\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6713 - acc: 0.6968 - val_loss: 0.6010 - val_acc: 0.7370\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6572 - acc: 0.7254 - val_loss: 0.6005 - val_acc: 0.7296\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6565 - acc: 0.7159 - val_loss: 0.5996 - val_acc: 0.7296\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6602 - acc: 0.7222 - val_loss: 0.5989 - val_acc: 0.7333\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6571 - acc: 0.7206 - val_loss: 0.5979 - val_acc: 0.7296\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6556 - acc: 0.7238 - val_loss: 0.5970 - val_acc: 0.7370\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6639 - acc: 0.7095 - val_loss: 0.5961 - val_acc: 0.7407\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6499 - acc: 0.7095 - val_loss: 0.5953 - val_acc: 0.7444\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6473 - acc: 0.7048 - val_loss: 0.5947 - val_acc: 0.7444\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6555 - acc: 0.7000 - val_loss: 0.5938 - val_acc: 0.7444\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6619 - acc: 0.7159 - val_loss: 0.5925 - val_acc: 0.7407\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6777 - acc: 0.7095 - val_loss: 0.5912 - val_acc: 0.7407\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6466 - acc: 0.7143 - val_loss: 0.5905 - val_acc: 0.7444\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6422 - acc: 0.7222 - val_loss: 0.5900 - val_acc: 0.7370\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6530 - acc: 0.7111 - val_loss: 0.5894 - val_acc: 0.7407\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6363 - acc: 0.7143 - val_loss: 0.5886 - val_acc: 0.7370\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6395 - acc: 0.7413 - val_loss: 0.5880 - val_acc: 0.7370\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6414 - acc: 0.7127 - val_loss: 0.5870 - val_acc: 0.7370\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6495 - acc: 0.7190 - val_loss: 0.5862 - val_acc: 0.7333\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6457 - acc: 0.7222 - val_loss: 0.5858 - val_acc: 0.7370\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6346 - acc: 0.7111 - val_loss: 0.5853 - val_acc: 0.7407\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6358 - acc: 0.7254 - val_loss: 0.5848 - val_acc: 0.7407\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7111 - val_loss: 0.5845 - val_acc: 0.7444\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6384 - acc: 0.7095 - val_loss: 0.5842 - val_acc: 0.7370\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6413 - acc: 0.7159 - val_loss: 0.5834 - val_acc: 0.7444\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6547 - acc: 0.7048 - val_loss: 0.5830 - val_acc: 0.7407\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6411 - acc: 0.7238 - val_loss: 0.5820 - val_acc: 0.7407\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6282 - acc: 0.7365 - val_loss: 0.5814 - val_acc: 0.7407\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6472 - acc: 0.7190 - val_loss: 0.5811 - val_acc: 0.7407\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6312 - acc: 0.7175 - val_loss: 0.5812 - val_acc: 0.7407\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6369 - acc: 0.7254 - val_loss: 0.5807 - val_acc: 0.7444\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6334 - acc: 0.7222 - val_loss: 0.5799 - val_acc: 0.7481\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6391 - acc: 0.7143 - val_loss: 0.5792 - val_acc: 0.7481\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6444 - acc: 0.7159 - val_loss: 0.5787 - val_acc: 0.7407\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6601 - acc: 0.6937 - val_loss: 0.5787 - val_acc: 0.7444\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6500 - acc: 0.7127 - val_loss: 0.5791 - val_acc: 0.7407\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6396 - acc: 0.7365 - val_loss: 0.5793 - val_acc: 0.7407\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6559 - acc: 0.7238 - val_loss: 0.5796 - val_acc: 0.7481\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6336 - acc: 0.7333 - val_loss: 0.5796 - val_acc: 0.7444\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6375 - acc: 0.7444 - val_loss: 0.5786 - val_acc: 0.7407\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6428 - acc: 0.7222 - val_loss: 0.5782 - val_acc: 0.7407\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6091 - acc: 0.7413 - val_loss: 0.5781 - val_acc: 0.7444\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6121 - acc: 0.7365 - val_loss: 0.5778 - val_acc: 0.7481\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6412 - acc: 0.7238 - val_loss: 0.5777 - val_acc: 0.7481\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6235 - acc: 0.7381 - val_loss: 0.5775 - val_acc: 0.7481\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6318 - acc: 0.7206 - val_loss: 0.5772 - val_acc: 0.7481\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6236 - acc: 0.7270 - val_loss: 0.5767 - val_acc: 0.7407\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6432 - acc: 0.7111 - val_loss: 0.5763 - val_acc: 0.7407\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6291 - acc: 0.7222 - val_loss: 0.5760 - val_acc: 0.7407\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6474 - acc: 0.7048 - val_loss: 0.5758 - val_acc: 0.7407\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6284 - acc: 0.7111 - val_loss: 0.5755 - val_acc: 0.7407\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6246 - acc: 0.7254 - val_loss: 0.5748 - val_acc: 0.7444\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6308 - acc: 0.7317 - val_loss: 0.5740 - val_acc: 0.7444\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6274 - acc: 0.7206 - val_loss: 0.5738 - val_acc: 0.7444\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6313 - acc: 0.7270 - val_loss: 0.5740 - val_acc: 0.7407\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6222 - acc: 0.7286 - val_loss: 0.5742 - val_acc: 0.7370\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6193 - acc: 0.7222 - val_loss: 0.5734 - val_acc: 0.7407\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6595 - acc: 0.7079 - val_loss: 0.5726 - val_acc: 0.7444\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6350 - acc: 0.7127 - val_loss: 0.5722 - val_acc: 0.7481\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6403 - acc: 0.7333 - val_loss: 0.5725 - val_acc: 0.7333\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6313 - acc: 0.7063 - val_loss: 0.5732 - val_acc: 0.7370\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6427 - acc: 0.7048 - val_loss: 0.5732 - val_acc: 0.7407\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6137 - acc: 0.7222 - val_loss: 0.5727 - val_acc: 0.7370\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6271 - acc: 0.7317 - val_loss: 0.5724 - val_acc: 0.7407\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6436 - acc: 0.6984 - val_loss: 0.5722 - val_acc: 0.7407\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6348 - acc: 0.7111 - val_loss: 0.5720 - val_acc: 0.7407\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6267 - acc: 0.7127 - val_loss: 0.5714 - val_acc: 0.7481\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6332 - acc: 0.7302 - val_loss: 0.5713 - val_acc: 0.7481\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6269 - acc: 0.7127 - val_loss: 0.5714 - val_acc: 0.7444\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6238 - acc: 0.7175 - val_loss: 0.5718 - val_acc: 0.7370\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6258 - acc: 0.7365 - val_loss: 0.5717 - val_acc: 0.7407\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6152 - acc: 0.7349 - val_loss: 0.5713 - val_acc: 0.7407\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6314 - acc: 0.7190 - val_loss: 0.5705 - val_acc: 0.7407\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6174 - acc: 0.7317 - val_loss: 0.5701 - val_acc: 0.7407\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6284 - acc: 0.7238 - val_loss: 0.5700 - val_acc: 0.7407\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6356 - acc: 0.7254 - val_loss: 0.5693 - val_acc: 0.7444\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6234 - acc: 0.7397 - val_loss: 0.5694 - val_acc: 0.7444\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6094 - acc: 0.7444 - val_loss: 0.5693 - val_acc: 0.7444\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6038 - acc: 0.7429 - val_loss: 0.5694 - val_acc: 0.7444\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6546 - acc: 0.7190 - val_loss: 0.5695 - val_acc: 0.7444\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6323 - acc: 0.7365 - val_loss: 0.5700 - val_acc: 0.7444\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6175 - acc: 0.7238 - val_loss: 0.5697 - val_acc: 0.7444\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6080 - acc: 0.7270 - val_loss: 0.5692 - val_acc: 0.7481\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6141 - acc: 0.7302 - val_loss: 0.5687 - val_acc: 0.7481\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6159 - acc: 0.7270 - val_loss: 0.5681 - val_acc: 0.7444\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6290 - acc: 0.7333 - val_loss: 0.5671 - val_acc: 0.7444\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6237 - acc: 0.7365 - val_loss: 0.5665 - val_acc: 0.7481\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6063 - acc: 0.7381 - val_loss: 0.5669 - val_acc: 0.7519\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6306 - acc: 0.7206 - val_loss: 0.5679 - val_acc: 0.7481\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6136 - acc: 0.7381 - val_loss: 0.5676 - val_acc: 0.7519\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6302 - acc: 0.7143 - val_loss: 0.5676 - val_acc: 0.7481\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6362 - acc: 0.7190 - val_loss: 0.5673 - val_acc: 0.7444\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6209 - acc: 0.7286 - val_loss: 0.5670 - val_acc: 0.7444\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6112 - acc: 0.7317 - val_loss: 0.5665 - val_acc: 0.7407\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6264 - acc: 0.7333 - val_loss: 0.5659 - val_acc: 0.7407\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6129 - acc: 0.7238 - val_loss: 0.5658 - val_acc: 0.7407\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6253 - acc: 0.7222 - val_loss: 0.5662 - val_acc: 0.7407\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6342 - acc: 0.7111 - val_loss: 0.5666 - val_acc: 0.7444\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6262 - acc: 0.7159 - val_loss: 0.5670 - val_acc: 0.7444\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6107 - acc: 0.7254 - val_loss: 0.5677 - val_acc: 0.7407\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6222 - acc: 0.7190 - val_loss: 0.5682 - val_acc: 0.7407\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6041 - acc: 0.7302 - val_loss: 0.5681 - val_acc: 0.7407\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6111 - acc: 0.7175 - val_loss: 0.5669 - val_acc: 0.7407\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6158 - acc: 0.7413 - val_loss: 0.5669 - val_acc: 0.7407\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6216 - acc: 0.7254 - val_loss: 0.5669 - val_acc: 0.7407\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6339 - acc: 0.7143 - val_loss: 0.5669 - val_acc: 0.7407\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6279 - acc: 0.7286 - val_loss: 0.5666 - val_acc: 0.7407\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6123 - acc: 0.7222 - val_loss: 0.5661 - val_acc: 0.7481\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6186 - acc: 0.7254 - val_loss: 0.5665 - val_acc: 0.7481\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6389 - acc: 0.7222 - val_loss: 0.5671 - val_acc: 0.7481\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6195 - acc: 0.7333 - val_loss: 0.5676 - val_acc: 0.7481\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6222 - acc: 0.7302 - val_loss: 0.5682 - val_acc: 0.7481\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6059 - acc: 0.7524 - val_loss: 0.5674 - val_acc: 0.7481\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6168 - acc: 0.7349 - val_loss: 0.5670 - val_acc: 0.7519\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6125 - acc: 0.7460 - val_loss: 0.5665 - val_acc: 0.7519\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6000 - acc: 0.7460 - val_loss: 0.5661 - val_acc: 0.7519\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5939 - acc: 0.7460 - val_loss: 0.5657 - val_acc: 0.7519\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6239 - acc: 0.7365 - val_loss: 0.5652 - val_acc: 0.7519\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6346 - acc: 0.7175 - val_loss: 0.5653 - val_acc: 0.7519\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6296 - acc: 0.7143 - val_loss: 0.5655 - val_acc: 0.7519\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6160 - acc: 0.7270 - val_loss: 0.5662 - val_acc: 0.7444\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6069 - acc: 0.7238 - val_loss: 0.5688 - val_acc: 0.7370\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6278 - acc: 0.7254 - val_loss: 0.5692 - val_acc: 0.7370\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6194 - acc: 0.7206 - val_loss: 0.5682 - val_acc: 0.7370\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6199 - acc: 0.7397 - val_loss: 0.5675 - val_acc: 0.7370\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6180 - acc: 0.7381 - val_loss: 0.5671 - val_acc: 0.7407\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6175 - acc: 0.7302 - val_loss: 0.5663 - val_acc: 0.7444\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6077 - acc: 0.7397 - val_loss: 0.5660 - val_acc: 0.7481\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6107 - acc: 0.7397 - val_loss: 0.5649 - val_acc: 0.7519\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6145 - acc: 0.7397 - val_loss: 0.5631 - val_acc: 0.7444\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6181 - acc: 0.7286 - val_loss: 0.5622 - val_acc: 0.7481\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6308 - acc: 0.7206 - val_loss: 0.5621 - val_acc: 0.7481\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6280 - acc: 0.7175 - val_loss: 0.5625 - val_acc: 0.7444\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6409 - acc: 0.7111 - val_loss: 0.5637 - val_acc: 0.7519\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6121 - acc: 0.7222 - val_loss: 0.5649 - val_acc: 0.7481\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6247 - acc: 0.7238 - val_loss: 0.5650 - val_acc: 0.7481\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6217 - acc: 0.7238 - val_loss: 0.5651 - val_acc: 0.7444\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6026 - acc: 0.7381 - val_loss: 0.5653 - val_acc: 0.7444\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6208 - acc: 0.7238 - val_loss: 0.5657 - val_acc: 0.7407\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6154 - acc: 0.7381 - val_loss: 0.5659 - val_acc: 0.7407\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6165 - acc: 0.7270 - val_loss: 0.5663 - val_acc: 0.7407\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6118 - acc: 0.7190 - val_loss: 0.5655 - val_acc: 0.7407\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6242 - acc: 0.7254 - val_loss: 0.5642 - val_acc: 0.7444\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6017 - acc: 0.7302 - val_loss: 0.5634 - val_acc: 0.7444\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6158 - acc: 0.7222 - val_loss: 0.5628 - val_acc: 0.7444\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6282 - acc: 0.7206 - val_loss: 0.5630 - val_acc: 0.7444\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6063 - acc: 0.7429 - val_loss: 0.5641 - val_acc: 0.7407\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6068 - acc: 0.7317 - val_loss: 0.5648 - val_acc: 0.7407\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5980 - acc: 0.7238 - val_loss: 0.5640 - val_acc: 0.7407\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6452 - acc: 0.7254 - val_loss: 0.5637 - val_acc: 0.7407\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6073 - acc: 0.7302 - val_loss: 0.5639 - val_acc: 0.7407\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6180 - acc: 0.7238 - val_loss: 0.5632 - val_acc: 0.7407\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6018 - acc: 0.7317 - val_loss: 0.5621 - val_acc: 0.7407\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6191 - acc: 0.7302 - val_loss: 0.5616 - val_acc: 0.7407\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6010 - acc: 0.7460 - val_loss: 0.5614 - val_acc: 0.7407\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6072 - acc: 0.7317 - val_loss: 0.5616 - val_acc: 0.7481\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6031 - acc: 0.7317 - val_loss: 0.5626 - val_acc: 0.7444\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6152 - acc: 0.7413 - val_loss: 0.5636 - val_acc: 0.7481\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6234 - acc: 0.7190 - val_loss: 0.5647 - val_acc: 0.7481\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6130 - acc: 0.7333 - val_loss: 0.5657 - val_acc: 0.7481\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6345 - acc: 0.7111 - val_loss: 0.5657 - val_acc: 0.7444\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6015 - acc: 0.7492 - val_loss: 0.5663 - val_acc: 0.7481\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6161 - acc: 0.7333 - val_loss: 0.5663 - val_acc: 0.7444\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6176 - acc: 0.7270 - val_loss: 0.5659 - val_acc: 0.7444\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6110 - acc: 0.7333 - val_loss: 0.5654 - val_acc: 0.7444\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6129 - acc: 0.7254 - val_loss: 0.5653 - val_acc: 0.7444\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6149 - acc: 0.7365 - val_loss: 0.5644 - val_acc: 0.7407\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6110 - acc: 0.7206 - val_loss: 0.5642 - val_acc: 0.7444\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6315 - acc: 0.7175 - val_loss: 0.5636 - val_acc: 0.7481\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5892 - acc: 0.7397 - val_loss: 0.5634 - val_acc: 0.7444\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5937 - acc: 0.7270 - val_loss: 0.5626 - val_acc: 0.7444\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6189 - acc: 0.7270 - val_loss: 0.5624 - val_acc: 0.7444\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6033 - acc: 0.7381 - val_loss: 0.5625 - val_acc: 0.7481\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5925 - acc: 0.7397 - val_loss: 0.5622 - val_acc: 0.7407\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6175 - acc: 0.7365 - val_loss: 0.5617 - val_acc: 0.7407\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5905 - acc: 0.7492 - val_loss: 0.5631 - val_acc: 0.7407\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6181 - acc: 0.7206 - val_loss: 0.5634 - val_acc: 0.7407\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6159 - acc: 0.7254 - val_loss: 0.5627 - val_acc: 0.7444\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6178 - acc: 0.7254 - val_loss: 0.5625 - val_acc: 0.7444\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5980 - acc: 0.7397 - val_loss: 0.5627 - val_acc: 0.7444\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5971 - acc: 0.7460 - val_loss: 0.5615 - val_acc: 0.7444\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6069 - acc: 0.7349 - val_loss: 0.5608 - val_acc: 0.7481\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6212 - acc: 0.7190 - val_loss: 0.5605 - val_acc: 0.7519\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5889 - acc: 0.7365 - val_loss: 0.5611 - val_acc: 0.7481\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6154 - acc: 0.7238 - val_loss: 0.5614 - val_acc: 0.7519\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6180 - acc: 0.7238 - val_loss: 0.5617 - val_acc: 0.7481\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6327 - acc: 0.7143 - val_loss: 0.5635 - val_acc: 0.7481\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6068 - acc: 0.7365 - val_loss: 0.5642 - val_acc: 0.7519\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6084 - acc: 0.7429 - val_loss: 0.5642 - val_acc: 0.7444\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6160 - acc: 0.7349 - val_loss: 0.5641 - val_acc: 0.7444\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6040 - acc: 0.7349 - val_loss: 0.5637 - val_acc: 0.7444\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5983 - acc: 0.7476 - val_loss: 0.5640 - val_acc: 0.7407\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6023 - acc: 0.7333 - val_loss: 0.5647 - val_acc: 0.7370\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6018 - acc: 0.7444 - val_loss: 0.5657 - val_acc: 0.7407\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6084 - acc: 0.7302 - val_loss: 0.5648 - val_acc: 0.7407\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5801 - acc: 0.7587 - val_loss: 0.5636 - val_acc: 0.7407\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6071 - acc: 0.7460 - val_loss: 0.5623 - val_acc: 0.7407\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5982 - acc: 0.7397 - val_loss: 0.5609 - val_acc: 0.7407\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6096 - acc: 0.7222 - val_loss: 0.5612 - val_acc: 0.7481\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6027 - acc: 0.7317 - val_loss: 0.5614 - val_acc: 0.7444\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6089 - acc: 0.7317 - val_loss: 0.5624 - val_acc: 0.7407\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5964 - acc: 0.7397 - val_loss: 0.5649 - val_acc: 0.7444\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6086 - acc: 0.7460 - val_loss: 0.5659 - val_acc: 0.7370\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6270 - acc: 0.7238 - val_loss: 0.5651 - val_acc: 0.7370\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5976 - acc: 0.7413 - val_loss: 0.5648 - val_acc: 0.7407\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6054 - acc: 0.7460 - val_loss: 0.5632 - val_acc: 0.7370\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6212 - acc: 0.7270 - val_loss: 0.5635 - val_acc: 0.7333\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6141 - acc: 0.7270 - val_loss: 0.5630 - val_acc: 0.7296\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6196 - acc: 0.7286 - val_loss: 0.5627 - val_acc: 0.7296\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6107 - acc: 0.7175 - val_loss: 0.5622 - val_acc: 0.7333\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6130 - acc: 0.7429 - val_loss: 0.5612 - val_acc: 0.7333\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6068 - acc: 0.7365 - val_loss: 0.5605 - val_acc: 0.7333\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6079 - acc: 0.7302 - val_loss: 0.5600 - val_acc: 0.7370\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5871 - acc: 0.7524 - val_loss: 0.5590 - val_acc: 0.7444\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5865 - acc: 0.7476 - val_loss: 0.5580 - val_acc: 0.7407\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5917 - acc: 0.7476 - val_loss: 0.5574 - val_acc: 0.7407\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5938 - acc: 0.7397 - val_loss: 0.5569 - val_acc: 0.7444\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6062 - acc: 0.7429 - val_loss: 0.5568 - val_acc: 0.7444\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6174 - acc: 0.7492 - val_loss: 0.5574 - val_acc: 0.7481\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6062 - acc: 0.7381 - val_loss: 0.5581 - val_acc: 0.7481\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5922 - acc: 0.7556 - val_loss: 0.5591 - val_acc: 0.7481\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6123 - acc: 0.7492 - val_loss: 0.5600 - val_acc: 0.7481\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6005 - acc: 0.7397 - val_loss: 0.5605 - val_acc: 0.7444\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6184 - acc: 0.7333 - val_loss: 0.5613 - val_acc: 0.7556\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6142 - acc: 0.7365 - val_loss: 0.5624 - val_acc: 0.7481\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6131 - acc: 0.7381 - val_loss: 0.5635 - val_acc: 0.7407\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6005 - acc: 0.7381 - val_loss: 0.5633 - val_acc: 0.7407\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6242 - acc: 0.7270 - val_loss: 0.5637 - val_acc: 0.7444\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6124 - acc: 0.7302 - val_loss: 0.5636 - val_acc: 0.7444\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6212 - acc: 0.7349 - val_loss: 0.5635 - val_acc: 0.7444\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6132 - acc: 0.7381 - val_loss: 0.5645 - val_acc: 0.7407\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6036 - acc: 0.7413 - val_loss: 0.5658 - val_acc: 0.7407\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6171 - acc: 0.7460 - val_loss: 0.5663 - val_acc: 0.7370\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6052 - acc: 0.7444 - val_loss: 0.5680 - val_acc: 0.7370\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5983 - acc: 0.7333 - val_loss: 0.5679 - val_acc: 0.7370\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6276 - acc: 0.7159 - val_loss: 0.5665 - val_acc: 0.7370\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6061 - acc: 0.7333 - val_loss: 0.5651 - val_acc: 0.7370\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6215 - acc: 0.7254 - val_loss: 0.5639 - val_acc: 0.7370\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5937 - acc: 0.7397 - val_loss: 0.5630 - val_acc: 0.7370\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6080 - acc: 0.7397 - val_loss: 0.5631 - val_acc: 0.7370\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.7317 - val_loss: 0.5645 - val_acc: 0.7259\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6003 - acc: 0.7365 - val_loss: 0.5652 - val_acc: 0.7296\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5984 - acc: 0.7508 - val_loss: 0.5661 - val_acc: 0.7333\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5954 - acc: 0.7476 - val_loss: 0.5660 - val_acc: 0.7333\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6048 - acc: 0.7302 - val_loss: 0.5677 - val_acc: 0.7333\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6184 - acc: 0.7238 - val_loss: 0.5685 - val_acc: 0.7333\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6019 - acc: 0.7397 - val_loss: 0.5674 - val_acc: 0.7407\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5979 - acc: 0.7349 - val_loss: 0.5672 - val_acc: 0.7444\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5947 - acc: 0.7429 - val_loss: 0.5667 - val_acc: 0.7444\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5817 - acc: 0.7429 - val_loss: 0.5660 - val_acc: 0.7481\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6092 - acc: 0.7365 - val_loss: 0.5659 - val_acc: 0.7481\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6176 - acc: 0.7413 - val_loss: 0.5658 - val_acc: 0.7444\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6158 - acc: 0.7143 - val_loss: 0.5661 - val_acc: 0.7481\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6097 - acc: 0.7365 - val_loss: 0.5657 - val_acc: 0.7407\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5872 - acc: 0.7429 - val_loss: 0.5661 - val_acc: 0.7444\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6168 - acc: 0.7349 - val_loss: 0.5654 - val_acc: 0.7444\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6050 - acc: 0.7381 - val_loss: 0.5642 - val_acc: 0.7481\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6081 - acc: 0.7317 - val_loss: 0.5634 - val_acc: 0.7444\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5744 - acc: 0.7524 - val_loss: 0.5627 - val_acc: 0.7444\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6133 - acc: 0.7349 - val_loss: 0.5615 - val_acc: 0.7444\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6115 - acc: 0.7317 - val_loss: 0.5609 - val_acc: 0.7519\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6073 - acc: 0.7349 - val_loss: 0.5612 - val_acc: 0.7556\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6207 - acc: 0.7381 - val_loss: 0.5621 - val_acc: 0.7481\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5974 - acc: 0.7349 - val_loss: 0.5636 - val_acc: 0.7444\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6000 - acc: 0.7349 - val_loss: 0.5648 - val_acc: 0.7444\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5908 - acc: 0.7413 - val_loss: 0.5654 - val_acc: 0.7481\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6264 - acc: 0.7238 - val_loss: 0.5657 - val_acc: 0.7481\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6036 - acc: 0.7381 - val_loss: 0.5660 - val_acc: 0.7481\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6086 - acc: 0.7206 - val_loss: 0.5666 - val_acc: 0.7444\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6098 - acc: 0.7206 - val_loss: 0.5667 - val_acc: 0.7333\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6233 - acc: 0.7222 - val_loss: 0.5662 - val_acc: 0.7444\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5978 - acc: 0.7444 - val_loss: 0.5651 - val_acc: 0.7481\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6233 - acc: 0.7349 - val_loss: 0.5662 - val_acc: 0.7481\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6063 - acc: 0.7349 - val_loss: 0.5672 - val_acc: 0.7370\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6047 - acc: 0.7317 - val_loss: 0.5683 - val_acc: 0.7296\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6171 - acc: 0.7302 - val_loss: 0.5688 - val_acc: 0.7296\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6062 - acc: 0.7302 - val_loss: 0.5694 - val_acc: 0.7333\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6048 - acc: 0.7397 - val_loss: 0.5691 - val_acc: 0.7333\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5913 - acc: 0.7333 - val_loss: 0.5687 - val_acc: 0.7370\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6137 - acc: 0.7381 - val_loss: 0.5694 - val_acc: 0.7444\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6116 - acc: 0.7333 - val_loss: 0.5688 - val_acc: 0.7444\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5981 - acc: 0.7397 - val_loss: 0.5678 - val_acc: 0.7444\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6093 - acc: 0.7317 - val_loss: 0.5673 - val_acc: 0.7407\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6028 - acc: 0.7476 - val_loss: 0.5686 - val_acc: 0.7444\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5884 - acc: 0.7492 - val_loss: 0.5695 - val_acc: 0.7407\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6057 - acc: 0.7460 - val_loss: 0.5707 - val_acc: 0.7333\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6249 - acc: 0.7444 - val_loss: 0.5725 - val_acc: 0.7296\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6140 - acc: 0.7238 - val_loss: 0.5727 - val_acc: 0.7259\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5949 - acc: 0.7492 - val_loss: 0.5724 - val_acc: 0.7259\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5975 - acc: 0.7349 - val_loss: 0.5711 - val_acc: 0.7296\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5888 - acc: 0.7397 - val_loss: 0.5689 - val_acc: 0.7296\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6126 - acc: 0.7333 - val_loss: 0.5687 - val_acc: 0.7333\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6156 - acc: 0.7286 - val_loss: 0.5683 - val_acc: 0.7296\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5940 - acc: 0.7460 - val_loss: 0.5669 - val_acc: 0.7333\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5997 - acc: 0.7524 - val_loss: 0.5651 - val_acc: 0.7370\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6054 - acc: 0.7460 - val_loss: 0.5642 - val_acc: 0.7481\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6248 - acc: 0.7190 - val_loss: 0.5646 - val_acc: 0.7481\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5981 - acc: 0.7444 - val_loss: 0.5654 - val_acc: 0.7481\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6013 - acc: 0.7429 - val_loss: 0.5676 - val_acc: 0.7370\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6004 - acc: 0.7444 - val_loss: 0.5681 - val_acc: 0.7370\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5896 - acc: 0.7556 - val_loss: 0.5692 - val_acc: 0.7370\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5999 - acc: 0.7476 - val_loss: 0.5706 - val_acc: 0.7333\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5951 - acc: 0.7302 - val_loss: 0.5705 - val_acc: 0.7333\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6133 - acc: 0.7349 - val_loss: 0.5695 - val_acc: 0.7333\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6038 - acc: 0.7381 - val_loss: 0.5696 - val_acc: 0.7333\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5954 - acc: 0.7381 - val_loss: 0.5687 - val_acc: 0.7296\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5977 - acc: 0.7365 - val_loss: 0.5678 - val_acc: 0.7333\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6090 - acc: 0.7302 - val_loss: 0.5664 - val_acc: 0.7370\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6014 - acc: 0.7302 - val_loss: 0.5665 - val_acc: 0.7370\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6096 - acc: 0.7222 - val_loss: 0.5666 - val_acc: 0.7333\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6025 - acc: 0.7429 - val_loss: 0.5679 - val_acc: 0.7296\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5758 - acc: 0.7460 - val_loss: 0.5687 - val_acc: 0.7296\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5925 - acc: 0.7556 - val_loss: 0.5684 - val_acc: 0.7296\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6033 - acc: 0.7365 - val_loss: 0.5676 - val_acc: 0.7296\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6008 - acc: 0.7254 - val_loss: 0.5669 - val_acc: 0.7296\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5966 - acc: 0.7429 - val_loss: 0.5658 - val_acc: 0.7333\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6008 - acc: 0.7444 - val_loss: 0.5643 - val_acc: 0.7259\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6082 - acc: 0.7222 - val_loss: 0.5640 - val_acc: 0.7259\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6064 - acc: 0.7444 - val_loss: 0.5640 - val_acc: 0.7222\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6064 - acc: 0.7349 - val_loss: 0.5640 - val_acc: 0.7259\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6104 - acc: 0.7397 - val_loss: 0.5637 - val_acc: 0.7259\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5915 - acc: 0.7508 - val_loss: 0.5646 - val_acc: 0.7259\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5899 - acc: 0.7429 - val_loss: 0.5685 - val_acc: 0.7296\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6024 - acc: 0.7333 - val_loss: 0.5698 - val_acc: 0.7259\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6089 - acc: 0.7333 - val_loss: 0.5701 - val_acc: 0.7259\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6138 - acc: 0.7270 - val_loss: 0.5699 - val_acc: 0.7259\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6034 - acc: 0.7333 - val_loss: 0.5698 - val_acc: 0.7259\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6108 - acc: 0.7286 - val_loss: 0.5708 - val_acc: 0.7259\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6154 - acc: 0.7238 - val_loss: 0.5712 - val_acc: 0.7222\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6130 - acc: 0.7254 - val_loss: 0.5705 - val_acc: 0.7259\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5957 - acc: 0.7476 - val_loss: 0.5694 - val_acc: 0.7259\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5950 - acc: 0.7333 - val_loss: 0.5709 - val_acc: 0.7222\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5994 - acc: 0.7302 - val_loss: 0.5715 - val_acc: 0.7222\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5881 - acc: 0.7476 - val_loss: 0.5703 - val_acc: 0.7222\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5722 - acc: 0.7571 - val_loss: 0.5681 - val_acc: 0.7222\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6078 - acc: 0.7365 - val_loss: 0.5658 - val_acc: 0.7296\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6079 - acc: 0.7333 - val_loss: 0.5653 - val_acc: 0.7296\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6122 - acc: 0.7302 - val_loss: 0.5661 - val_acc: 0.7222\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5930 - acc: 0.7381 - val_loss: 0.5665 - val_acc: 0.7222\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6121 - acc: 0.7190 - val_loss: 0.5676 - val_acc: 0.7259\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5928 - acc: 0.7460 - val_loss: 0.5683 - val_acc: 0.7259\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6087 - acc: 0.7444 - val_loss: 0.5690 - val_acc: 0.7296\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5936 - acc: 0.7476 - val_loss: 0.5681 - val_acc: 0.7296\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6017 - acc: 0.7476 - val_loss: 0.5667 - val_acc: 0.7296\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6115 - acc: 0.7365 - val_loss: 0.5667 - val_acc: 0.7296\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6111 - acc: 0.7381 - val_loss: 0.5655 - val_acc: 0.7296\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6022 - acc: 0.7381 - val_loss: 0.5654 - val_acc: 0.7259\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6039 - acc: 0.7270 - val_loss: 0.5644 - val_acc: 0.7259\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6084 - acc: 0.7333 - val_loss: 0.5644 - val_acc: 0.7259\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5929 - acc: 0.7413 - val_loss: 0.5643 - val_acc: 0.7296\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6053 - acc: 0.7333 - val_loss: 0.5656 - val_acc: 0.7333\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6025 - acc: 0.7381 - val_loss: 0.5671 - val_acc: 0.7296\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6216 - acc: 0.7349 - val_loss: 0.5686 - val_acc: 0.7296\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5997 - acc: 0.7349 - val_loss: 0.5700 - val_acc: 0.7296\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5873 - acc: 0.7349 - val_loss: 0.5702 - val_acc: 0.7296\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6000 - acc: 0.7270 - val_loss: 0.5678 - val_acc: 0.7259\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6005 - acc: 0.7286 - val_loss: 0.5671 - val_acc: 0.7296\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6068 - acc: 0.7302 - val_loss: 0.5666 - val_acc: 0.7333\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6127 - acc: 0.7317 - val_loss: 0.5665 - val_acc: 0.7259\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5834 - acc: 0.7524 - val_loss: 0.5660 - val_acc: 0.7222\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5939 - acc: 0.7540 - val_loss: 0.5674 - val_acc: 0.7222\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6001 - acc: 0.7429 - val_loss: 0.5674 - val_acc: 0.7222\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6123 - acc: 0.7381 - val_loss: 0.5682 - val_acc: 0.7259\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6078 - acc: 0.7286 - val_loss: 0.5687 - val_acc: 0.7222\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5938 - acc: 0.7460 - val_loss: 0.5695 - val_acc: 0.7259\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5918 - acc: 0.7365 - val_loss: 0.5691 - val_acc: 0.7222\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5898 - acc: 0.7413 - val_loss: 0.5670 - val_acc: 0.7222\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5975 - acc: 0.7349 - val_loss: 0.5645 - val_acc: 0.7222\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6130 - acc: 0.7476 - val_loss: 0.5642 - val_acc: 0.7259\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5961 - acc: 0.7333 - val_loss: 0.5654 - val_acc: 0.7259\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5821 - acc: 0.7492 - val_loss: 0.5659 - val_acc: 0.7259\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6025 - acc: 0.7492 - val_loss: 0.5672 - val_acc: 0.7222\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5956 - acc: 0.7413 - val_loss: 0.5677 - val_acc: 0.7222\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6061 - acc: 0.7365 - val_loss: 0.5697 - val_acc: 0.7222\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6088 - acc: 0.7286 - val_loss: 0.5699 - val_acc: 0.7259\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6016 - acc: 0.7413 - val_loss: 0.5710 - val_acc: 0.7259\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5917 - acc: 0.7492 - val_loss: 0.5718 - val_acc: 0.7259\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5967 - acc: 0.7349 - val_loss: 0.5706 - val_acc: 0.7259\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6011 - acc: 0.7413 - val_loss: 0.5688 - val_acc: 0.7222\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6069 - acc: 0.7413 - val_loss: 0.5690 - val_acc: 0.7222\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5989 - acc: 0.7333 - val_loss: 0.5724 - val_acc: 0.7222\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6002 - acc: 0.7349 - val_loss: 0.5749 - val_acc: 0.7296\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5850 - acc: 0.7540 - val_loss: 0.5768 - val_acc: 0.7259\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6093 - acc: 0.7206 - val_loss: 0.5807 - val_acc: 0.7296\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6160 - acc: 0.7286 - val_loss: 0.5808 - val_acc: 0.7259\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6122 - acc: 0.7302 - val_loss: 0.5788 - val_acc: 0.7259\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6080 - acc: 0.7254 - val_loss: 0.5755 - val_acc: 0.7222\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5909 - acc: 0.7397 - val_loss: 0.5734 - val_acc: 0.7296\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6037 - acc: 0.7333 - val_loss: 0.5735 - val_acc: 0.7370\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5915 - acc: 0.7571 - val_loss: 0.5732 - val_acc: 0.7370\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5908 - acc: 0.7508 - val_loss: 0.5742 - val_acc: 0.7333\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6128 - acc: 0.7365 - val_loss: 0.5734 - val_acc: 0.7259\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5916 - acc: 0.7270 - val_loss: 0.5744 - val_acc: 0.7259\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6357 - acc: 0.7206 - val_loss: 0.5731 - val_acc: 0.7222\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5916 - acc: 0.7349 - val_loss: 0.5722 - val_acc: 0.7222\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5963 - acc: 0.7349 - val_loss: 0.5720 - val_acc: 0.7259\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6150 - acc: 0.7238 - val_loss: 0.5706 - val_acc: 0.7222\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6161 - acc: 0.7254 - val_loss: 0.5713 - val_acc: 0.7259\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6208 - acc: 0.7397 - val_loss: 0.5726 - val_acc: 0.7296\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5997 - acc: 0.7397 - val_loss: 0.5750 - val_acc: 0.7333\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5965 - acc: 0.7476 - val_loss: 0.5768 - val_acc: 0.7333\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5955 - acc: 0.7603 - val_loss: 0.5781 - val_acc: 0.7333\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5870 - acc: 0.7492 - val_loss: 0.5761 - val_acc: 0.7333\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6039 - acc: 0.7238 - val_loss: 0.5742 - val_acc: 0.7259\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6028 - acc: 0.7365 - val_loss: 0.5730 - val_acc: 0.7222\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6047 - acc: 0.7381 - val_loss: 0.5736 - val_acc: 0.7296\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6029 - acc: 0.7429 - val_loss: 0.5756 - val_acc: 0.7296\n"
     ]
    }
   ],
   "source": [
    "train_data = data[:int(0.7*len(data))]\n",
    "val_data = data[int(0.7*len(data)):]\n",
    "def Decision_model():\n",
    "    inputs = tf.keras.layers.Input(shape=(2),name = 'd0')\n",
    "    x1 = tf.keras.layers.Dense(units=20,activation='relu',\n",
    "                                   name = 'd1')(inputs)\n",
    "    x1 = tf.keras.layers.Dropout(0.5)(x1)\n",
    "    x1 = tf.keras.layers.Dense(units=10,activation='relu',\n",
    "                                   name = 'd2')(x1)\n",
    "    outputs = tf.keras.layers.Dense(units=3,activation='softmax',\n",
    "                                   name = 'd3')(x1)\n",
    "    #模型在后面训练、使用\n",
    "    model_train = keras.Model(inputs = inputs, outputs = outputs,name = \"multi-cate\")\n",
    "    return model_train\n",
    "Decision = Decision_model()\n",
    "####################################################模型编译&计算####################################################################\n",
    "\n",
    "Decision.compile(keras.optimizers.Adam(lr = 0.001),metrics=['acc'],loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "\n",
    "history_D = Decision.fit(train_data[:,:2],train_data[:,2],validation_data=(val_data[:,:2],val_data[:,2]),epochs=500,batch_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7352078 ,  0.5931659 , -0.75154734],\n",
       "       [-0.699453  ,  1.1146278 ,  0.2949298 ],\n",
       "       [ 0.16172773, -0.7675157 ,  0.13551141],\n",
       "       [-0.6960918 , -0.79622525,  0.10581598],\n",
       "       [-0.1235126 , -0.38630882,  0.9311485 ],\n",
       "       [-0.21070063, -0.49759236,  0.95861465],\n",
       "       [-1.2269756 , -0.01212703,  0.31633127],\n",
       "       [-0.45387587, -0.31037644,  0.92670286],\n",
       "       [ 0.11030975,  0.45583838, -0.76999855],\n",
       "       [ 0.72775537, -0.48554283, -0.46468857]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_set = (Decision.variables[4]).numpy()\n",
    "beta_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37613076, -0.17900391, -0.2435637 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_set = (Decision.variables[5]).numpy()\n",
    "bias_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intercept the model whose output is ten features, calculate u, and calculate alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_model = tf.keras.Model(inputs = Decision.input, outputs = Decision.get_layer('d2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.376131  , -0.17900401, -0.24356359], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fai_j = truncated_model.predict(train_data[:,:2])\n",
    "nu_j = np.mean(fai_j,0)\n",
    "sum_betajk_nu = []\n",
    "# calcuate nu\n",
    "for i in range(3):\n",
    "    sum_i = np.sum(beta_set[:,i]*nu_j)\n",
    "    sum_betajk_nu.append(sum_i)\n",
    "alpha = np.zeros_like(beta_set)\n",
    "# calculate alpha\n",
    "for i in range(3):\n",
    "    for j in range(10):\n",
    "        alpha[j,i] = 1/10*(bias_set[i]+sum_betajk_nu[i])-beta_set[j,i]*nu_j[j]\n",
    "np.sum(alpha,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1579889 , -0.17758304,  0.31306192],\n",
       "       [ 0.49286118, -0.98112786, -0.32346418],\n",
       "       [-0.19840066,  0.16249351, -0.04878948],\n",
       "       [-0.13200526,  0.15987888, -0.04567809],\n",
       "       [-0.1820113 ,  0.10873082, -0.06060906],\n",
       "       [-0.18506166,  0.09919026, -0.03761275],\n",
       "       [ 1.243911  ,  0.11331377, -0.40602168],\n",
       "       [ 0.14224535,  0.32301444, -0.70589316],\n",
       "       [-0.30613908, -0.40114394,  0.80754775],\n",
       "       [-0.6572575 ,  0.4142292 ,  0.26389515]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w+ and w-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate w\n",
    "i_fai_j = truncated_model.predict(data_test[:,:2])\n",
    "i_fai_j = i_fai_j.reshape(len(i_fai_j),-1,1)\n",
    "w = i_fai_j * beta_set + alpha\n",
    "w = w.reshape(len(w),10,3,1) # 10 is the output number of truncated_model  \n",
    "zeros = np.zeros_like(w)\n",
    "# w_plus\n",
    "w_plus_pre = np.concatenate((w,zeros),-1)\n",
    "w_plus = np.sum(np.max(w_plus_pre,-1),-2)\n",
    "# w_minus\n",
    "w_minus_pre = np.concatenate((-w,zeros),-1)\n",
    "w_minus = np.sum(np.max(w_minus_pre,-1),-2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mass({$\\theta_k$}) and mass({$A$})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_theta_k_pre\n",
    "prod_l = np.zeros_like(w_minus) # prod_l is the continuous multiplication in the first formula in proposition 1\n",
    "for i in range(3):\n",
    "    prod_l[:,[i]] = (1-np.exp(-w_minus[:,[(i+1)%3]]))*(1-np.exp(-w_minus[:,[(i+2)%3]]))\n",
    "\n",
    "m_theta_k_pre = np.exp(-w_minus)*(np.exp(w_plus)-1+prod_l)\n",
    "\n",
    "# m_A_pre\n",
    "# A_set[0] represents the set {0,1}\n",
    "A_set = [[0,1],[0,2],[1,2],[0,1,2]] # A_set is the second continuous multiplication in the second formula in proposition 1\n",
    "A_not_set = [list(set([0,1,2])-set(i)) for i in A_set] # A_not_set is the second continuous multiplication in the second formula in proposition 1\n",
    "for i in range(len(A_set)):\n",
    "    if i == 0:\n",
    "        # in A\n",
    "        prod_theta_k_in_A_j = 1\n",
    "        for j in A_set[i]:\n",
    "            prod_theta_k_in_A_j = prod_theta_k_in_A_j * np.exp(-w_minus[:,[j]])\n",
    "        prod_theta_k_in_A = prod_theta_k_in_A_j\n",
    "        # not in A\n",
    "        prod_theta_k_not_in_A_j = 1\n",
    "        for j in A_not_set[i]:\n",
    "            prod_theta_k_not_in_A_j = prod_theta_k_not_in_A_j * (1-np.exp(-w_minus[:,[j]]))\n",
    "        prod_theta_k_not_in_A = prod_theta_k_not_in_A_j\n",
    "    else:\n",
    "        # in A\n",
    "        prod_theta_k_in_A_j = 1\n",
    "        for j in A_set[i]:\n",
    "            prod_theta_k_in_A_j = prod_theta_k_in_A_j * np.exp(-w_minus[:,[j]])\n",
    "        prod_theta_k_in_A = np.concatenate((prod_theta_k_in_A,prod_theta_k_in_A_j),1)\n",
    "        # not in A\n",
    "        prod_theta_k_not_in_A_j = 1\n",
    "        for j in A_not_set[i]:\n",
    "            prod_theta_k_not_in_A_j = prod_theta_k_not_in_A_j * (1-np.exp(-w_minus[:,[j]]))\n",
    "        \n",
    "        if i < len(A_set)-1:\n",
    "            prod_theta_k_not_in_A = np.concatenate((prod_theta_k_not_in_A,prod_theta_k_not_in_A_j),1)\n",
    "        else:\n",
    "            prod_theta_k_not_in_A = np.concatenate((prod_theta_k_not_in_A,np.ones((prod_theta_k_not_in_A.shape[0],1))),1)\n",
    "m_A_pre = prod_theta_k_in_A*prod_theta_k_not_in_A\n",
    "\n",
    "# m\n",
    "m_pre = np.concatenate((m_theta_k_pre,m_A_pre),1)\n",
    "m = m_pre/np.sum(m_pre,1,keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether pl can restore probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.842100435788476e-05"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_set = [[0],[1],[2],[0,1],[0,2],[1,2],[0,1,2]]\n",
    "pl = np.zeros((data_test.shape[0],3))\n",
    "pl[:,[0]] = m[:,[0]]+m[:,[3]]+m[:,[4]]+m[:,[6]]\n",
    "pl[:,[1]] = m[:,[1]]+m[:,[3]]+m[:,[5]]+m[:,[6]]\n",
    "pl[:,[2]] = m[:,[2]]+m[:,[4]]+m[:,[5]]+m[:,[6]]\n",
    "p = np.zeros((data_test.shape[0],3))\n",
    "p = pl/np.sum(pl,1,keepdims=True)\n",
    "np.sum(np.abs(p-Decision.predict(data_test[:,:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p38tf25",
   "language": "python",
   "name": "p38tf25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
